{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_o5kuDALEdd"
   },
   "source": [
    "# This is Nifty 500 Correlation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odUe1m0ELEde"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1901,
     "status": "ok",
     "timestamp": 1606790909006,
     "user": {
      "displayName": "theweirdguy__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfwqYA-QyIPcIY4pXKaX4XvhmPlsfwDz899Gehj5A=s64",
      "userId": "14895470682289769220"
     },
     "user_tz": -330
    },
    "id": "o6Ahcn62LEde"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "from datetime import date\n",
    "# from nsetools import Nse\n",
    "from matplotlib import style\n",
    "from nsepy.history import get_history\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1BSGdoPLEdf"
   },
   "source": [
    "## SAVE THE NSE_TICKER_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1613,
     "status": "ok",
     "timestamp": 1606790933471,
     "user": {
      "displayName": "theweirdguy__",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjfwqYA-QyIPcIY4pXKaX4XvhmPlsfwDz899Gehj5A=s64",
      "userId": "14895470682289769220"
     },
     "user_tz": -330
    },
    "id": "qh0bgeBnLEdf"
   },
   "outputs": [],
   "source": [
    "def save_nse_500_tickers():\n",
    "    list_of_stock_codes = list(pd.read_csv('nifty_list/ind_nifty500list.csv')['Symbol'])\n",
    "    return list_of_stock_codes\n",
    "\n",
    "def save_nse_200_tickers():\n",
    "    list_of_stock_codes = list(pd.read_csv('nifty_list/ind_nifty200list.csv')['Symbol'])\n",
    "    list_of_stock_codes.remove('ACC')\n",
    "    return list_of_stock_codes\n",
    "\n",
    "def save_nse_100_tickers():\n",
    "    list_of_stock_codes = list(pd.read_csv('nifty_list/ind_nifty100list.csv')['Symbol'])\n",
    "    return list_of_stock_codes\n",
    "\n",
    "def save_nse_50_tickers():\n",
    "    list_of_stock_codes = list(pd.read_csv('nifty_list/ind_nifty50list.csv')['Symbol'])\n",
    "    return list_of_stock_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_history(symbol=\"ADANIPORTS\", start=date(2015,1,1), end=date(2015,1,31))\n",
    "# web.DataReader(\"ADANIPORTS\" + \".NS\", 'yahoo', date(2021,1,1), date(2021,5,31))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OdfR57BLEdf"
   },
   "source": [
    "## Fetch the Historical Data from NSEPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTkY-AcYLEdf"
   },
   "outputs": [],
   "source": [
    "def get_data_from_nsepy(ticker_fetch_function):\n",
    "    \n",
    "    # Create a directory if it does not exist.\n",
    "    if not os.path.exists(nse_directory):\n",
    "        os.makedirs(nse_directory)\n",
    "    \n",
    "    tickers = ticker_fetch_function\n",
    "    \n",
    "    \n",
    "    start = dt.datetime(2016, 1, 1)\n",
    "    end = dt.datetime(2021, 5, 19)\n",
    "\n",
    "    for ticker in tickers:\n",
    "        print (\"Feching the\", ticker)\n",
    "        if not os.path.exists(nse_directory + '/{}.csv'.format(ticker)):\n",
    "            \n",
    "            try:\n",
    "                df_nse = get_history(symbol=ticker, start=start, end=end)\n",
    "#                 df_nse = web.DataReader(ticker + \".NS\", 'yahoo', start, end)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "            \n",
    "            df_nse.to_csv(nse_directory + '/{}.csv'.format(ticker))\n",
    "            print('Dont have {}'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGsiVWSALEdf",
    "outputId": "3fc4e80e-5b1b-4ed0-fa71-7e32ccee40df"
   },
   "outputs": [],
   "source": [
    "nse_directory = 'nse_data_50'\n",
    "get_data_from_nsepy(save_nse_50_tickers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKUks7J6LEdi"
   },
   "source": [
    "## Compile the data into one Adjusted close of NIFTY500 Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ENcvSPILEdi"
   },
   "outputs": [],
   "source": [
    "def compile_data(ticker_fetch_function):\n",
    "    \n",
    "    tickers = ticker_fetch_function\n",
    "   \n",
    "    \n",
    "    # Remove invaid stock quotes.\n",
    "    if tickers in ['ASTERDM', 'FEDERALBNK', 'ACC', '3MINDIA']:\n",
    "        tickers.remove('ASTERDM')\n",
    "        tickers.remove('FEDERALBNK')\n",
    "        tickers.remove('ACC')\n",
    "        tickers.remove('3MINDIA')\n",
    "        \n",
    "    \n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    for count, ticker in enumerate(tickers):\n",
    "        df = pd.read_csv('nse_data_50/{}.csv'.format(ticker))\n",
    "        \n",
    "        df.set_index('Date', inplace = True)\n",
    "        print(df.columns)\n",
    "        \n",
    "        columns_to_be_dropped = ['Symbol', 'Series', 'Prev Close', 'Open', \n",
    "                                 'High', 'Low', 'Last', 'VWAP', 'Volume', \n",
    "                                 'Turnover', 'Trades', 'Deliverable Volume',\n",
    "                                 '%Deliverble']\n",
    "\n",
    "#         columns_to_be_dropped = ['Open', 'High', 'Low', 'Volume', 'Close']\n",
    "        \n",
    "        df.rename(columns = {'Close' : ticker}, inplace = True)\n",
    "        df.drop(columns_to_be_dropped, 1, inplace = True)\n",
    "        df.fillna(0, inplace=True)\n",
    "        \n",
    "        print(df.columns)\n",
    "        \n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "            print(df)\n",
    "        else:\n",
    "            print(df)\n",
    "            main_df = main_df.join(df, how='outer')\n",
    "        \n",
    "        if count % 10 == 0:\n",
    "            print(count)\n",
    "    \n",
    "    print(main_df.head())\n",
    "    main_df.to_csv('nifty50_joined_closes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAyMARHyLEdi",
    "outputId": "214f486b-9330-40c7-a51c-c9e82ccb2206"
   },
   "outputs": [],
   "source": [
    "compile_data(save_nse_50_tickers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFBIPZNCLEdi"
   },
   "source": [
    "## Visualization of Co-relation among companies from nifty-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsg2GU22LEdi"
   },
   "outputs": [],
   "source": [
    "def visualize_data():\n",
    "    df = pd.read_csv('nifty50_joined_closes.csv')\n",
    "    df_corr = df.corr()\n",
    "    df_corr.to_csv('correlation_data')\n",
    "    print (df_corr.head())\n",
    "    \n",
    "    data = df_corr.values\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    heatmap = ax.pcolor(data, cmap='Spectral')\n",
    "    fig.colorbar(heatmap)\n",
    "    ax.set_xticks(np.arange(data.shape[0]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(data.shape[1]) + 0.5, minor=False)\n",
    "    \n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "    \n",
    "    column_labels = df_corr.columns\n",
    "    row_labels = df_corr.index\n",
    "    \n",
    "    ax.set_xticklabels(column_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    plt.xticks(rotation = 90)\n",
    "    heatmap.set_clim(-1,1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWyOMRZ5LEdi",
    "outputId": "7ef579ec-07e8-404a-ae12-95042758e121"
   },
   "outputs": [],
   "source": [
    "visualize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0MjtivyLEdi"
   },
   "outputs": [],
   "source": [
    "# pd.read_csv(\"correlation_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCyEdAcpLEdi"
   },
   "source": [
    "## Process data for label and create target and featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a02hQif_LEdi"
   },
   "outputs": [],
   "source": [
    "def process_data_for_labels(ticker):\n",
    "    hm_days = 7\n",
    "    df = pd.read_csv('nifty50_joined_closes.csv', index_col = 0)\n",
    "    tickers = df.columns.values.tolist()\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    for i in range(1, hm_days+1):\n",
    "        df['{}_{}d'.format(ticker, i)] = (df[ticker].shift(-i) - df[ticker]) / df[ticker]\n",
    "        \n",
    "    df.fillna(0, inplace= True)\n",
    "    return tickers, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXz9SSGsLEdi"
   },
   "outputs": [],
   "source": [
    "def buy_sell_hold(*args):\n",
    "    cols = [c for c in args]\n",
    "    requirement = 0.030\n",
    "    for col in cols:\n",
    "        if col > requirement:\n",
    "            return 1\n",
    "        if col < -requirement:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlBLXOR9LEdi"
   },
   "outputs": [],
   "source": [
    "def extract_fetauresets(ticker):\n",
    "    tickers, df = process_data_for_labels(ticker)\n",
    "    \n",
    "    df['{}_target'.format(ticker)] = list(map (buy_sell_hold, df['{}_1d'.format(ticker)],\n",
    "                                                              df['{}_2d'.format(ticker)],\n",
    "                                                              df['{}_3d'.format(ticker)],\n",
    "                                                              df['{}_4d'.format(ticker)],\n",
    "                                                              df['{}_5d'.format(ticker)],\n",
    "                                                              df['{}_6d'.format(ticker)],\n",
    "                                                              df['{}_7d'.format(ticker)]))\n",
    "    \n",
    "    vals = df['{}_target'.format(ticker)].values.tolist()\n",
    "    str_vals = [str(i) for i in vals]\n",
    "#     print('Data Spread: ', Counter(str_vals))\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df_vals = df[[ticker for ticker in tickers]]\n",
    "    df_vals = df_vals.replace([np.inf, -np.inf], np.nan)\n",
    "    df_vals.fillna(0, inplace=True)\n",
    "    \n",
    "    X = df_vals.values\n",
    "    y = df['{}_target'.format(ticker)].values\n",
    "    \n",
    "    return X, y, df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oe4ZsEKtLEdi"
   },
   "source": [
    "## Finally, Perform your Algorithm's Corelation on different Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzZiZ-4BLEdi"
   },
   "outputs": [],
   "source": [
    "def do_ml(ticker):\n",
    "    X, y, df = extract_fetauresets(ticker)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    \n",
    "    estimator = []\n",
    "    estimator.append(('LR',  \n",
    "                  LogisticRegression(solver ='lbfgs',  \n",
    "                                     max_iter = 80, multi_class = \"auto\"))) \n",
    "    estimator.append(('SVC', SVC(gamma ='auto', probability = True))) \n",
    "    estimator.append(('DTC', DecisionTreeClassifier())) \n",
    "    \n",
    "#     clf = VotingClassifier(estimators = estimator, voting ='soft')\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    confidence = clf.score(X_test, y_test)\n",
    "    print(\"Accuracy\", confidence)\n",
    "    \n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    print(\"Predicted Spread: \", Counter(predictions))\n",
    "    \n",
    "    return(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXdK4pdXLEdi"
   },
   "outputs": [],
   "source": [
    "X, y, df = extract_fetauresets(\"ADANIPORTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svqy0wt0LEdj"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BscnZ8WOLEdj"
   },
   "source": [
    "##  Buy sell hold data on Top 50 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EI5idSP6LEdj"
   },
   "outputs": [],
   "source": [
    "tickers = save_nse_50_tickers()\n",
    "hold_buy_sell_df  = pd.DataFrame()\n",
    "for i in tickers:\n",
    "    X, y, df = extract_fetauresets(i)\n",
    "    hold_buy_sell_df[i] = df.loc[df.index > '2020-06-07'][i+\"_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gi0SsH3dLEdj"
   },
   "outputs": [],
   "source": [
    "hold_buy_sell_df.loc['2021-05-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSWbn7NdLEdj",
    "outputId": "33732e31-80c5-4887-ce27-1143063b8a84"
   },
   "outputs": [],
   "source": [
    "do_ml(\"TCS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I868XznILEdj"
   },
   "source": [
    "# Analyzing the peer stocks in IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tv4X2KwLEdj"
   },
   "outputs": [],
   "source": [
    "# Analysing your Competitors Stocks\n",
    "PEER_STOCKS = [\"TCS\", \"INFY\", \"WIPRO\", \"HCLTECH\"]\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "for ticker in PEER_STOCKS:\n",
    "    print(ticker)\n",
    "    df = pd.read_csv('nse_data_200/{}.csv'.format(ticker))\n",
    "\n",
    "    # Compile the data over a interval\n",
    "    df = df[(df['Date'] > '2021-1-1') & (df['Date'] <= '2021-5-10')]\n",
    "\n",
    "    df.set_index('Date', inplace = True)\n",
    "\n",
    "    columns_to_be_dropped = ['Symbol', 'Series', 'Prev Close', 'Open', \n",
    "                             'High', 'Low', 'Last', 'VWAP', 'Volume', \n",
    "                             'Turnover', 'Trades', 'Deliverable Volume',\n",
    "                             '%Deliverble']\n",
    "\n",
    "    df.rename(columns = {'Close' : ticker}, inplace = True)\n",
    "    df.drop(columns_to_be_dropped, 1, inplace = True)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    if main_df.empty:\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df = main_df.join(df, how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G71LIIzALEdj"
   },
   "outputs": [],
   "source": [
    "pct_comp = main_df.pct_change()\n",
    "corr = pct_comp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoNYh4q2LEdj"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pylJAEpoLEdj"
   },
   "outputs": [],
   "source": [
    "scatter_matrix(pct_comp, diagonal='kde', figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XygQJn7yLEdj"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# Adjusting the size of matplotlib\n",
    "import matplotlib as mpl\n",
    "mpl.rc('figure', figsize=(8, 7))\n",
    "mpl.__version__\n",
    "\n",
    "# Adjusting the style of matplotlib\n",
    "style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3zpI9JYLEdj"
   },
   "outputs": [],
   "source": [
    "plt.imshow(corr, cmap='hot', interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr)), corr.columns)\n",
    "plt.yticks(range(len(corr)), corr.columns);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69zwXY_cLEdj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "Nifty500CorrelationAlgorithm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
